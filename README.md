# EATM
Embedding Author-Topic Model
The author-topic model analyzes the relationships between authors, documents, topics, and words. A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors. However, existing author-topic models fail to learn interpretable topics when working with large vocabularies and author list. To this end, we develop the embedded author-topic model (EATM), a generative model of documents that marries traditional author-topic models with embedding representation. In particular, we use inner product of embedding vectors to replace distribution parameters and fit an inference network to prior author distribution different from tradition models. It outperforms existing document models, such as author-topic latent Dirichlet allocation, in terms of both topic quality and predictive performance. 
